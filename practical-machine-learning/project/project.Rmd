---
title: "Practical Machine Learning Project"
author: "Patricio Del Boca"
date: "22/11/2015"
output: html_document
---

## Project Summary

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

__The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set.__

```{r, results='hide', message=FALSE}
library(ggplot2)
library(caret)
library(reshape2)
library(doMC)
set.seed(31415) # Reproducible Research
setwd("~/Repos/datasciencecoursera/practical-machine-learning/project")
```


## Get Data
To be fully reproducible, I've included code to donwload the data.

```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
    dir.create("./data")
}
if (!file.exists(trainFile)) {
    download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
    download.file(testUrl, destfile=testFile, method="curl")
}
trainingRaw <- read.csv('./data//pml-training.csv')
testingRaw <- read.csv('./data//pml-testing.csv')

```


## Clean Data
Since both files has the same structure, Ive created a function to clean the 
data and keep the code DRY.

```{r, cache=TRUE}
cleanData <- function(dataset){
    dataset <- dataset[, colSums(is.na(dataset)) == 0]
    dataset <- dataset[, !grepl("timestamp", colnames(dataset))]
    dataset <- dataset[, !grepl("X", colnames(dataset))]
    dataset <- dataset[, !grepl("window", colnames(dataset))]
    dataset <- dataset[, !grepl("user_name", colnames(dataset))]
    classe <- dataset$classe
    dataset <- dataset[,sapply(dataset, is.numeric)]
    dataset$classe <- classe
    dataset
}

training <- cleanData(trainingRaw)
sum(!complete.cases(training)) # Check if all rows are completed
testing <- cleanData(testingRaw)
sum(!complete.cases(testing)) # Check if all rows are completed
```

## Exploratory Data Analysis

The data seems to be ready to be used to train a model. From the PCA analysis
we can conclude that the classes seems separable without further 
pre-processing. Check appendix for detailed graphs.

__Note:__ *PCA also separates correcly between user_names. This means that an algorithm can identify wheter a particular person is using the device or someone else is.*

## Train Model
I will use Random Forest since it is a straight forward method to tackle 
classification problems. 

#### Split Data:
Split the train data to evaluate the performance.
```{r}
indexTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
trainData <- training[indexTrain,]
testingData <- training[-indexTrain,]
```

#### Parameters:
 - CV: To avoid overfitting I will use a cross validation method with k = 7. 
 - Allow Parallel: To get the most of my cores and train faster.
 - Number of Trees: 250 it's a good boiler plate number for training RF.

```{r, cache=TRUE}
registerDoMC(cores = detectCores() - 1) # This will use all of the cores but one

## All subsequent models are then run in parallel
trControl <- trainControl(method="cv", 7)
fit <- train(classe ~ ., method="rf", trControl=trControl,
             data=trainData, allowParallel=TRUE, ntree=250)

fit$results
fit$finalModel
```

General Performance:

* Accuracy: __99.22%__
* OOB Estimate of Error Rate: __0.68%__
* No. of variables tried at each split: __2__


## Prediction on Testing Data
Now we test out model in the Testing Data:
```{r, cache=TRUE}
pred <- predict(fit, testingData)
confusionMatrix(testingData$classe, pred)
oos <- (1 - confusionMatrix(testingData$classe, pred)$overall[1]) * 100
```

Prediction Performance:

* Accuracy: __99.47%__
* OOSE: __0.26%__ `(1 - accuracy)`
 
It seems that there isn't a clear pattern on the Errors of the predictor (See Apendix), so we conclude our modeling phase.


## Prediction on New Data:
This will predict the data to submit in the exercise
```{r}
predNewData <- predict(fit, testing[,-which(names(testing) %in% c("problem_id"))])
predNewData

if (!file.exists("./predictions")) {
    dir.create("./predictions")
}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./predictions/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(predNewData)
```

## Conclusion

Random Forest is one of the state-of-the-art Machine Learning algorithms. Without furter pre-processing it was able to predict with high accuracy and relatively low OOSE. This demonstrate the prediction power of the algorithms and the amount of applications they have to solve all kind of problems.

## Apendix
#### Principal Component Analysis
```{r, echo=FALSE}

preProc <- preProcess(training, method="pca", pcaComp = 2)
pca <- predict(preProc, training)
ggplot(pca, aes(x=PC1, y=PC2,colour=classe)) + geom_point() +
  ggtitle("PCA with classe as target.")

pca$user_name <- trainingRaw$user_name 
ggplot(pca, aes(x=PC1, y=PC2,colour=user_name)) + geom_point() +
  ggtitle("PCA with user_name as target.")

```

#### Highly correlated variables
```{r}
M <- abs(cor(training[,-53]))
diag(M) <- 0
M <- ifelse(M>0.8, 1, 0)
qplot(x=Var1, y=Var2, data=melt(M), fill=value, geom="tile") + 
  ggtitle("Variables with correlation higher than 0.8.")
```

#### Random Forest
```{r, echo=FALSE}
plot(fit, main = "Accuracy vs Selected Predictors")
plot(fit$finalModel, main = "Number of Trees vs Error Rate")
```

#### Prediction Errors:
```{r, echo=FALSE}
pca <- predict(preProc, testingData)
pca$predicted <- (testingData$classe == pred)
ggplot(pca, aes(x=PC1, y=PC2,colour=predicted)) + geom_point() +
  ggtitle("Prediction Performance.")
```





