myData
class(myData)
cnames <- c("patient","age","weight", "bp", "rating","test")
colnames(myData) <- cnames
myData
5+7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1,9,3.14)
?c
z
c(z,555,z)
z * 2 + 100
mySqrt <- sqrt(z-1)
mySqrt
myDiv <- z / mySqrt
myDiv
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
1:20
pi:10
15:1
?':'
?`:`
seq(1,20)
seq(0,10,by=0,5)
seq(0,10,by=0.5)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along=my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2),each = 10)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
print tbl_df
print(tbl_df)
cran
?manip
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country+)
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
cran
select(cran,-(1:size))
select(cran,-(X:size))
filter(cran,package == "swirl")
filter(cran,r_version == "3.1.1", country == "US")
swirl()
filter(cran,r_version == "3.1.1", country == "US")
ls()
remove(list=ls())
ls(9)
ls()
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
file_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(file_url,destfile = "/tmp/data.csv",method = "curl")
download.file(file_url,destfile = "/tmp/data.csv")
download.file(file_url,destfile = "/tmp/data.csv", method = "auto")
?download.file
download.file(file_url,destfile = "/tmp/data.csv", method = "wget")
data <- read.csv("/tmp//data.csv")
head(data)
names(data)
summary(data)
dim(data)
data$VAL[q:10]
data$VAL[1:10]
values <- data$VAL[!is.na(data$VAL)]
values[1:10]
length(values[values >= 14])
length(values)
values > 14
(values > 14)[1:10]
values[1:10]
values_greater_than_14 <- values[values >= 14]
length(values[values = 24])
length(values[values == 24])
(values[values == 24])
data[data$VAL == 24]
houses <- data
rm(data)
houses[1:10]
houses[houses$VAL == 24]
houses$FES[1:10]
file2_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(file2_url,"/tmp/gas.xlsx",method = "wget")
library(xlsx)
install.packages("xlsx")
library(xlsx)
library("xlsx")
library("xlsx2")
install.packages("xlsx2")
data <- read.table("/tmp/gas.xlsx")
head(data)
install.packages("xlsx")
library(xlsx)
library(xlsx)
library(rJava)
install.packages("rJava")
install.packages("rJava")
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
file_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(file_url,"/tmp/data.csv",method = "get")
download.file(file_url,"/tmp/data.csv",method = "wget")
acs <- read.csv("/tmp/data.csv")
dim(acs)
head(acs)
dim(acs)
str(acs)
install.packages("sqldf")
library('sqldf')
sqldf("select * from acs")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1, AGEP from acs where AGEP < 50")
sqldf("select pwgtp1, AEGP from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1, AGEP from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
unique(acs$AGEP)
identical(unique(acs$AGEP),sqldf("select unique * from acs"))
?identical
subset1 <- unique(acs$AGEP)
subset1
subset1 <- sqldf("select unique * from acs")
sqldf("select unique * from acs")
sqldf("select unique * from acs")
sqldf("select distinct pwgtp1 from acs")
sqldf("select AGEP where unique from acs")
sqldf("select distinct AGEP from acs")
identical(subset1,sqldf("select distinct AGEP from acs"))
str(unique(acs$AGEP))
str(sqldf("select distinct AGEP from acs"))
install.packages('httr')
library('httr')
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html <- GET(url)
html
html[10]
html[,10]
str(htl)
str(html)
html$content
content <- content(html,as="text")
?content
content
content <- content(html,as="parsed")
install.packages('XML')
library('XML')
content <- content(html,as="text")
content
parsed_content(content)
parsed_content(content, as = 'parsed')
parsed(content, as = 'parsed')
content
content <- content(html,type = "text/xml")
install.packages('XML')
install.packages('XML')
content <- content(html,type = "text/xml")
content
library('XML')
parsed_html <- htmlParse(content, asText = TRUE)
parsed_html
str(parsed_html)
parsed_html[1]
parsed_html[1,]
parsed_html
nchar(parsed_html)
con = url(url)
htmlCode = readLines(con)
htmlCode
htmlCode[]10
htmlCode[10]
close(con)
htmlCode[10] htmlCode[20] htmlCode[30] htmlCode[100]
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
con = url(url)
htmlCode = readLines(con)
close(con)
htmlCode[10]; htmlCode[20]; htmlCode[30]; htmlCode[100]
length(htmlCode[10])
as.Text(htmlCode[10])
as.character(htmlCode[10])
lenght(as.character(htmlCode[10]))
length(as.character(htmlCode[10]))
nchar(htmlCode[10])
typeof(htmlCode[10])
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
?download.file
download.file(url5,"/tmp/data5.csv",method = "wget")
url5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url5,"/tmp/data5.csv",method = "wget")
data5 <- read.delim("/tmp/data5.csv")
head(data5)
str(data5)
data5 <- read.delim2("/tmp/data5.csv")
str(data5)
?read.delim
data5 <- read.delim2("/tmp/data5.csv",header = TRUE)
str(data5)
dim(data5)
data5 <- read.delim("/tmp/data5.csv",header = TRUE)
dim(data5)
dim(data5)
dec = ".", fill = TRUE, comment.char = "", ...)
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"",
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"",
dec = ".", fill = TRUE, comment.char = "", ...)
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "", ...)
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5 <- read.delim(data5, header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5 <- read.delim("/tmp/data5.csv", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
dim(data5)
dim(data5)
download.file(url5,"/tmp/data5.foo",method = "wget")
data5 <- read.delim("/tmp/data5.foo", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5
str(data5)
data5 <- read.delim("/tmp/data5.for", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
url5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url5,"/tmp/data5.for",method = "wget")
data5 <- read.delim("/tmp/data5.for", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5
str(data5)
data5 <- read.delim2("/tmp/data5.for", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
str(data5)
data5 <- read.delim2("/tmp/data5.for")
str(data5)
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4)
str(data5)
str(data5)
download.file(url5,"/tmp/data5.for",method = "wget")
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4)
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
str(data5)
sum(data5$V4)
ube <- function(x, n) {
x^3
}
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
x <- Sys.Date()
x
typeof(x)
x <- Sys.tate()
time <- Sys.time()
typeof(time)
as.POSIXct(time)
time2 <- as.POSIXct(time)
time2$
names(time2)
time2 <- as.POSIXlt(time)
names(time2)
time2
names(unclass(time2)
)
class(time2)
typeof(time2)
time2$sec
weekdays(time2)
weekdays(time)
time2
time3 <- as.POSIXlt(Sys.time())
time3 > time2
time3$isdt
time3$isdst
time3$zone
time3$gmtoff
tiempo <- "January 10, 2012 10:40"
strptime(tiempo, %B %d)
strptime(tiempo, %B %d, %Y %H:%M)
Sys.setenv(LANG = "en")
strptime(tiempo, %B %d, %Y %H:%M)
defaults write org.R-project.R force.LANG en_US.UTF-8
defaults write org.R-project.R force.LANG en_US.UTF-8
help(Startup)
Sys.getenv("LANG")
Sys.setenv(LANG = "en_US.UTF-8")
Sys.getenv("LANG")
q()
Sys.getenv("LANG")
Sys.setenv(LANG = "en_US.UTF-8")
Sys.getenv("LANG")
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
p <- function(x){x+x}
p(2)
makeVector(vec)
vec <- makeVector()
vec$set(2)
vec$get
vec$get()
a <- makeVector(c(1,2,3,4))
a$get()
a$getmean()
cachemean(a)
a$getmean()  # this is only to show you that the mean has been stored and does not affect anything
cachemean(a)
a$set(c(10,20,30,40))
a$getmean()
cachemean(a)
cachemean(a)
a$get()
a$setmean(0)  # do NOT call setmean() directly despite it being accessible for the reason you will see next
a$getmean()
a$get()
cachemean(a)
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
source("cachematrix.R")
makeCacheMatrix <- function(matrix = matrix()) {
# store inverse value
inverse <- NULL
# set the original matrix and reset inverse
set <- function(y) {
matrix <<- y
inverse <<- NULL
}
# get the original matrix
get <- function() matrix
# set inverse value
set_inverse <- function(inv) inverse <<- inv
# get inverse value
get_inverse <- function() inverse
# Returns a list of the 4 functions, this is the special "matrix"
list(set = set, get = get,
set_inverse = set_inverse,
get_inverse = get_inverse)
}
## This function computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated (and
## the matrix has not changed), then the cachesolve should retrieve the
## inverse from the cache.
cacheSolve <- function(special_matrix, ...) {
inverse <- special_matrix$get_inverse()
if(!is.null(inverse)) {
message("getting cached data")
return(inverse)
}
data <- special_matrix$get()
inverse <- solve(data, ...)
special_matrix$set_inverse(inverse)
inverse
}
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
amatrix$get()         # Returns original matrix
cacheSolve(amatrix)   # Computes, caches, and returns    matrix inverse
amatrix$get_inverse()  # Returns matrix inverse
cacheSolve(amatrix)   # Returns cached matrix inverse using previously computed matrix inverse
amatrix$set(matrix(c(0,5,99,66), nrow=2, ncol=2)) # Modify existing matrix
cacheSolve(amatrix)   # Computes, caches, and returns new matrix inverse
amatrix$get()         # Returns matrix
amatrix$getinverse()  # Returns matrix inverse
amatrix$get_inverse()  # Returns matrix inverse
library('swirl')
install_from_swirl("Getting and Cleaning Data")
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head()
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
tbl_df
cran
?manip
select(cran, ip_id, package, country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran,r_version == "3.1.1", country == "US")
?Comparison
filter(cran,r_version <= "3.1.1", country == "IN")
filter(cran,r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country =="IN")
filter(cran,size>100500,r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2 <- select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id)
)
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <- select(cran, ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2 ^ 10)
mutate(cran3, correct_size = size + 1000)
summarize(cran,avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
submit
submit()
pack_sum
quantile(pack_sum$count,probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts,20)
arragnge(top_counts,desc(count))
arrange(top_counts,desc(count))
quantile(pack_sum$unique,probs = 0.99)
top_unique <- filter(pack_sum,unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
submit()
print
submit()
submit()
cran %>%
select(ip_id,country,package,size) %>%
print()
submit()
submit()
submit()
submit()
setwd("~/Repos/datasciencecoursera/r-programming/assignment 1")
source('submitscript1.R')
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
