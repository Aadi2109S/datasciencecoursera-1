---
title: "Practical Machine Learning Project"
author: "pdelboca"
date: "22/11/2015"
output: html_document
---

# Project Summary

```{r}
library(ggplot2)
library(caret)
library(reshape2)
library(doMC)
set.seed(31415) # Reproducible Research
setwd("~/Repos/datasciencecoursera/practical-machine-learning/project")
```


# Get Data
To be fully reproducible, I've included code to donwload the data.

```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
    dir.create("./data")
}
if (!file.exists(trainFile)) {
    download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
    download.file(testUrl, destfile=testFile, method="curl")
}
trainingRaw <- read.csv('./data//pml-training.csv')
testingRaw <- read.csv('./data//pml-testing.csv')

```


# Clean Data
Since both files has the same structure, Ive created a function to clean the 
data and keep the code DRY.

```{r, echo=FALSE, cache=TRUE}
cleanData <- function(dataset){
    dataset <- dataset[, colSums(is.na(dataset)) == 0]
    dataset <- dataset[, !grepl("timestamp", colnames(dataset))]
    dataset <- dataset[, !grepl("X", colnames(dataset))]
    dataset <- dataset[, !grepl("window", colnames(dataset))]
    dataset <- dataset[, !grepl("user_name", colnames(dataset))]
    classe <- dataset$classe
    dataset <- dataset[,sapply(dataset, is.numeric)]
    dataset$classe <- classe
    dataset
}

training <- cleanData(trainingRaw)
sum(!complete.cases(training)) # Check if all rows are completed
testing <- cleanData(testingRaw)
sum(!complete.cases(testing)) # Check if all rows are completed
```

# Exploratory Data Analysis

The data seems to be ready to be used to train a model. From the PCA analysis
we can conclude that the classes seems separable without further 
pre-processing. Check appendix for detailed graphs.

# Train Model
I will use Random Forest since it is a straight forward method to tackle 
classification problems. 

### Split Data:
Split the train data to evaluate the performance.
```{r}
indexTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
trainData <- training[indexTrain,]
testingData <- training[-indexTrain,]
```

### Parameters:
 - *CV:* To avoid overfitting I will use a cross validation method with k = 7. 
 - *Allow Parallel:* To get the most of my cores and train faster.
 - *Number of Trees:* 250 it's a good boiler plate number for training RF.

```{r, cache=TRUE}
registerDoMC(cores = detectCores() - 1) # This will use all of the cores but one

## All subsequent models are then run in parallel
trControl <- trainControl(method="cv", 7)
fit <- train(classe ~ ., method="rf", trControl=trControl,
             data=trainData, allowParallel=TRUE, ntree=250)

fit$results
fit$finalModel
```

General Performance:
 - Accuracy: *99.22%*
 - OOB Estimate of Error Rate: *0.68%*
 - No. of variables tried at each split: *27*


# Prediction on Testing Data
Now we test out model in the Testing Data:
```{r, cache=TRUE}
pred <- predict(fit, testingData)
confusionMatrix(testingData$classe, pred)
oos <- (1 - confusionMatrix(testingData$classe, pred)$overall[1]) * 100
```

Prediction Performance:
 - Accuracy: *99.22%*
 - OOSE: *0.78%* `(1 - accuracy)`
 
It seems that there isn't a clear pattern on the Errors of the predictor (See Apendix), so we conclude our modeling phase.


# Prediction on New Data:

```{r}
predNewData <- predict(fit, testing[,-which(names(testing) %in% c("problem_id"))])
predNewData
```


# Apendix
### Principal Component Analysis
```{r}

preProc <- preProcess(training, method="pca", pcaComp = 2)
pca <- predict(preProc, training)
ggplot(pca, aes(x=PC1, y=PC2,colour=classe)) + geom_point()

pca$user_name <- trainingRaw$user_name 
ggplot(pca, aes(x=PC1, y=PC2,colour=user_name)) + geom_point()

```

### Highly correlated variables
```{r}
M <- abs(cor(training[,-53]))
qplot(x=Var1, y=Var2, data=melt(M), fill=value, geom="tile")
diag(M) <- 0
which(M > 0.8, , arr.ind = TRUE)
```

### Random Forest
```{r}
plot(fit, main = "Accuracy vs Selected Predictors")
plot(fit$finalModel, main = "Number of Trees vs Error Rate")
```

### Prediction Errors:
```{r}
pca <- predict(preProc, testingData)
pca$predicted <- (testingData$classe == pred)
ggplot(pca, aes(x=PC1, y=PC2,colour=predicted)) + geom_point() +
  ggtitle("Prediction Performance.")
```





